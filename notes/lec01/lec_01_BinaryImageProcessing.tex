% !TEX root=./../maha-dip-notes.tex
\chapter{Binary Image Processing}

\section{Introduction}

\dfn{Image Definition}{
An \textbf{image} is a projection of a 3D object onto a 2D surface. This dimensional reduction causes loss of certain 3D information, which is generally very hard to recover. 
}


\section{Image Formation}

The process of \textbf{image formation} models how a 3D scene is mapped to a 2D image plane through a camera model. A pinhole camera serves as the simplest abstraction to study this process.

\subsection{Pinhole Camera Model (2D)}
In the 2D case, the relation between a point $(X,Z)$ in the scene and its projection $(x)$ on the image plane is derived by similar triangles:

\vspace{1cm}


\begin{center}
\begin{tikzpicture}[scale=1.5]
  % Draw the image plane
  \draw[thick] (6,0) -- (6,2.2);
  \node[right] at (6,2.2) {Image Plane ($z=f$)};
  % Draw the image plane
  \draw[thick] (4,0) -- (4,2.2);
  \node[right] at (4.1,2.2) {Camera Plane};
  % Draw the optical axis
  \draw[dashed] (0,1) -- (8,1);
  \node[above] at (7.2,1) {Optical Axis};
  % Draw the pinhole (center of projection)
  \filldraw[black] (4,1) circle (0.06);
  % \node[above] at (4.6,0.6) {Pinhole $O$};
  % Draw the scene point (object) on the left
  \filldraw[blue] (0,2) circle (0.06);
  \node[above] at (0,2) {Scene Point $(X,Z)$};
  % Draw projection line from scene point to pinhole
  \draw[blue,thick] (0,2) -- (4,1);
  % Draw projection line from pinhole to image plane (right side)
  \draw[red,thick] (4,1) -- (6,0.5);
  % Draw the projected point on image plane
  \filldraw[red] (6,0.5) circle (0.06);
  \node[right] at (6,0.4) {Image Point $x$};
  % Label distances
  \draw[<->] (0,0.8) -- (4,0.8);
  \node[below] at (2,0.8) {$X$};
  \draw[<->] (-0.2,1) -- (-0.2,2);
  \node[left] at (-0.2,1.5) {$Z$};
  \draw[<->] (6.2,1) -- (6.2,0.5);
  \node[right] at (6.25,0.75) {$x$};
  \draw[<->] (6,1.2) -- (4,1.2);
  \node[above] at (5,1.2) {Focal Length $f$};
  % Draw focal length line
  \draw[dashed] (0,1) -- (4,1);
  \filldraw[black] (4,1) circle (0.04);
\end{tikzpicture}
\end{center}

\vspace{0.3cm}

\noindent from the diagram, we have:

\[
\frac{x}{f} = \frac{X}{Z}
\quad \Rightarrow \quad
x = f \cdot \frac{X}{Z}
\]
Here, $f$ is the focal length of the pinhole camera.


\nt{we use Capital letters for 3D coordinates and lowercase for 2D image coordinates and observe that the \textrm{Z} component is lost.}

\subsection{Pinhole Camera Model (3D)}
Extending to 3D coordinates $(X,Y,Z)$, the projection onto the image plane gives:
\[
x = f \cdot \frac{X}{Z}, \quad
y = f \cdot \frac{Y}{Z}
\]

\noindent This shows how 3D geometry is mapped to 2D via perspective projection.

\subsection{Homogeneous Coordinates}
Homogeneous coordinates are used to express projection as a matrix multiplication:
\[
\begin{bmatrix}x \\ y \\ 1 \end{bmatrix}
= \frac{1}{Z}
\begin{bmatrix}
f & 0 & 0 & 0 \\
0 & f & 0 & 0 \\
0 & 0 & 1 & 0
\end{bmatrix}
\begin{bmatrix} X \\ Y \\ Z \\ 1 \end{bmatrix}
\]

\nt{Homogeneous coordinates are crucial because they unify perspective projection, translation, and rotation into matrix multiplications.}

\subsection{Intrinsic Matrix}
The \textbf{intrinsic parameters} capture camera-specific properties such as focal length and principal point offset:
\[
K =
\begin{bmatrix}
f_x & 0 & c_x \\
0 & f_y & c_y \\
0 & 0 & 1
\end{bmatrix}
\]
where $(f_x,f_y)$ are focal lengths in pixel units and $(c_x,c_y)$ is the principal point.

\subsection{Extrinsic Matrix}
The \textbf{extrinsic parameters} describe the camera’s position and orientation in the world:
\[
M = [R|t]
\]
where $R$ is a $3\times 3$ rotation matrix and $t$ is a $3 \times 1$ translation vector.

\nt{
The rotation matrix $R$ can be defined using an angle $\alpha$ in 2D as:
\[
R(\alpha) = 
\begin{bmatrix}
\cos\alpha & -\sin\alpha \\
\sin\alpha & \cos\alpha
\end{bmatrix}
\]
This matrix rotates a point by $\alpha$ radians in the plane.
% }
% \nt{
In 3D, rotation can be performed about each axis using three matrices:
\[
R_x(\theta) = 
\begin{bmatrix}
1 & 0 & 0 \\
0 & \cos\theta & -\sin\theta \\
0 & \sin\theta & \cos\theta
\end{bmatrix}
% \]
% \[
\quad , \quad
R_y(\phi) = 
\begin{bmatrix}
\cos\phi & 0 & \sin\phi \\
0 & 1 & 0 \\
-\sin\phi & 0 & \cos\phi
\end{bmatrix}
% \]
% \[
\quad , \quad
R_z(\psi) = 
\begin{bmatrix}
\cos\psi & -\sin\psi & 0 \\
\sin\psi & \cos\psi & 0 \\
0 & 0 & 1
\end{bmatrix}
\]
A general 3D rotation can be represented by multiplying these matrices:
\[
R = R_z(\psi) R_y(\phi) R_x(\theta)
\]
where $\theta$, $\phi$, and $\psi$ are rotation angles about the $x$, $y$, and $z$ axes, respectively.

}

\subsection{Projection Matrix}
The complete mapping from 3D world coordinates to 2D image plane is:
\[
s \begin{bmatrix} u \\ v \\ 1 \end{bmatrix}
= K M 
\begin{bmatrix} X \\ Y \\ Z \\ 1 \end{bmatrix}
\]
with scaling factor $s$.  

\clm{Projection Matrix}{}
{The projection matrix $P = K @ M$ completely defines the mapping from world coordinates to image coordinates, which depends on the intrinsic and extrinsic parameters of the camera. (i.e., focal length, principal point, rotation, and translation vectors.)}

% \subsection{Camera Calibration}
\dfn{Camera Calibration}{The process of estimating the intrinsic and extrinsic parameters of a camera from observed images of a known calibration pattern.}
Calibration ensures accurate geometric measurements from images.


\section{Image Representation}

\subsection{Pixel Values}
A digital image is represented as a 2D array of \textbf{pixels (picture elements)}, each encoding intensity (grayscale) or color.


\dfn{Image \& Pixel}{%
An \textbf{image} is a 2D array $$I:\{0,\dots,M-1\}\times\{0,\dots,N-1\}\to\{0,\dots,K-1\}$$
Each element $I[i,j]$ is a \textbf{pixel} with \textbf{intensity} (gray level) in $\{0,\dots,K-1\}$, where, 0 represents black and $K-1$ represents white. For a 8 bit storage, $B = 8$, then maximum intensity can be calculated as $K = 2^B = 2^8 = 256$, $0$ represents black and $255$ represents white. \\

For normalized intensity, use $$I_n[i,j]=\frac{I[i,j]}{(K-1)}\in[0,1]$$.%
}

\subsection{Color Spaces}
Different \textbf{color spaces} represent pixel values differently:
\begin{itemize}
    \item RGB: additive primary colors.
    \item HSV: hue, saturation, value (closer to human perception).
    \item YCbCr: luminance and chrominance separation. (where Y is intensity)
\end{itemize}



\subsection{Feature Extraction and Descriptors}
\textbf{Features} capture essential information in images such as edges, corners, or textures.  
\textbf{Descriptors} encode features into numerical representations (e.g., SIFT, HOG) for matching and recognition.

\subsection{Sampling and Quantization}
The ideal irradiance signal is sampled on a discrete grid and quantized to a finite set of gray levels.
\begin{itemize}
    \item \textbf{Sampling:} Selecting discrete spatial points to represent an image.\\
    choose integer pixel sites $(i,j)$; the image becomes $I[i,j]$ on an $M\times N$ grid.
    \item \textbf{Quantization:} Mapping continuous intensity values into discrete levels \\
    map real intensities to $\{0,1,\dots,K-1\}$, e.g., $K=256$ for 8-bit grayscale.
\end{itemize}

\noindent \textbf{Binary images:} special case $K=2$ with intensities $\{0,1\}$ (or $\{0,255\}$ in 8-bit storage).



\nt{Undersampling causes aliasing; inadequate quantization leads to loss of detail.}

\subsection{Image Formats}
Typical resolutions include $256\times 256$, $512\times 512$, \textbf{1920x1080}, etc.%
As we can calculate the number of Bytes required to store these images, we find:

\begin{itemize}
    \item For $256\times 256$ images: $256 \times 256 \times 1 = 65,536$ Bytes (assuming 8-bit grayscale).
    \item For $512\times 512$ images: $512 \times 512 \times 1 = 262,144$ Bytes (assuming 8-bit grayscale).
    \item For $1920\times 1080$ images: $1920 \times 1080 \times 3 = 6,220,800$ Bytes (assuming 24-bit RGB).
\end{itemize}

which is nearly 6.3 MB for a full HD image (1920x1080 3-channel RGB image). 
Hence, image storage can be quite substantial, necessitating efficient compression techniques. \\

Few common \textbf{Formats} include:
\begin{itemize}
    \item JPEG: lossy compressed format. \\
    The most common for photographs to save space, as the human eye is less sensitive to high-frequency details. The compression is achieved by discarding some image data, but the benefit is a significantly reduced file size. (e.g. the full HD image (1920x1080) can be compressed from {\bf 6.3 MB} to around less than a {\bf 1 MB})
    \item PNG: lossless compression, supports transparency.
    \item BMP: uncompressed raster format.
    \item TIFF: flexible format supporting various compressions.
    \item GIF: supports animation and transparency (limited color palette).
    \item WEBP: modern format providing lossy and lossless compression.
    \item HEIF: high efficiency image format, supports advanced features.
    \item AVIF: image format based on AV1 compression, offering high quality at smaller file sizes.
    \item EXR: high dynamic range (HDR) image format, supports wide color gamuts and high bit depths.
    \item DNG: raw image format for digital photography, preserves original sensor data.
    \item PPM: portable pixmap format, simple uncompressed color image format.
\end{itemize}

\subsection{Binary Images and Thresholding}

\dfn{Binary Image}{
A \textbf{binary image} is an image that consists of only two colors, typically black and white. Each pixel in a binary image is represented by a single bit, where 0 represents black and 1 represents white.
}


\noindent The simplest method to obtain binary images is \textbf{thresholding}:
\[
B(x,y) = \begin{cases}
1 & I(x,y) \geq T \\
0 & I(x,y) < T
\end{cases}
\]
where $T$ is the threshold.

\subsection{Gray Level Histograms}
The histogram of grayscale values is a fundamental tool to analyze and design thresholding algorithms.

\clm{Histogram-based Thresholding}{}
{If the histogram shows two well-separated peaks, the optimal threshold lies near the valley between them.}



%==========================
\section{Histogram of an Image}
%==========================

\dfn{Gray-Level Histogram}{
A \textbf{gray-level histogram} is a representation of the distribution of pixel intensities in a grayscale image. It counts the number of pixels for each intensity level, providing insights into the image's contrast and brightness.
}
\paragraph{Mathematical Formulation}

Let a grayscale image be
$$I:\{0,\dots,M\!-\!1\}\times\{0,\dots,N\!-\!1\}\to\{0,\dots,K\!-\!1\}$$. 
The \emph{histogram} counts occurrences at each gray level, given as a function as 
$$H:\{0,\dots,K\!-\!1\}\to\{0,\dots,MN\}$$

such that 
$$ H(k) = \text{no of occurrences of gray level } k$$ 

where $k \in \{0,\dots,K-1\}$

\[
H(k) \;=\; \#\{(i,j): I[i,j]=k\} \qquad k=0,\dots,K-1
\]

also, 
\[
\sum_{k=0}^{K-1} H(k)=MN.
\]

\noindent The \emph{normalized histogram} (PMF) is $$p(k)=\tfrac{H(k)}{MN}$$

and $$\sum_k p(k)=1$$


\ex{Interpreting Histogram Shapes}{
Given an image whose histogram exhibits a tall peak near intensity $40$ (dark shades), and another smaller, broad peak near $200$ (bright shades), we deduce the image features a dark background with a bright foreground—ideal for segmentation via thresholding.

\begin{itemize}
\item \textbf{Dark image:} $p(k)$ concentrated near $k\approx 0$.
\item \textbf{Bright image:} $p(k)$ concentrated near $k\approx K\!-\!1$.
\item \textbf{Bimodal image:} two peaks (e.g., dark foreground on bright background) $\Rightarrow$ suitable for a \emph{single} global threshold.
\end{itemize}

\begin{center}
\begin{tikzpicture}
\begin{axis}[
  ybar, bar width=6pt, width=0.9\linewidth, height=5cm,
  ymin=0, ylabel={Count}, xlabel={Gray level $k$},
  xtick={0,32,64,96,128,160,192,224,255},
  xticklabel style={font=\footnotesize}, yticklabel style={font=\footnotesize},
  title={Example Bimodality (illustrative data)}
]
\addplot coordinates {(0,5) (16,9) (32,20) (48,35) (64,40) (80,30) (96,18) (112,12)
(128,10) (144,12) (160,20) (176,35) (192,42) (208,36) (224,24) (240,12) (255,6)};
\end{axis}
\end{tikzpicture}
\end{center}
}

% Gray level image histograms are foundational tools in digital image processing, providing a statistical representation of the distribution of pixel intensities in an image. The histogram constitutes an array or plot where the $x$-axis denotes possible gray levels (e.g., $0$ to $255$ for 8-bit images), and the $y$-axis gives the count or probability of each gray level's appearance within the image.

\nt{Understanding the histogram profile assists in identifying whether an image is underexposed, overexposed, well-contrasted, or subject to other illumination artifacts.}


\paragraph{Types of Histograms and Their Interpretation}
Different histogram profiles relate directly to the visual impression and underlying properties of an image:
\begin{itemize}
    \item \textbf{Bright Images:} Most pixel values clustered towards the higher end of the gray level range.
    \item \textbf{Dark Images:} Values crowded in the lower end, leading to overall darker visual output.
    \item \textbf{Dual Peak Model:} Exhibits two pronounced peaks, often corresponding to distinct foreground and background regions; common in images fit for binarization.
    \item \textbf{Flat Histogram:} Pixels uniformly distributed across gray levels—rare in natural images, may occur in images heavily corrupted with noise.
    \item \textbf{Equal Histograms:} Result from histogram equalization operations to improve contrast.
\end{itemize}

\ex{Histogram Interpretation}{
\begin{itemize}
    \item A \textbf{bright image} shows histogram concentrated on high intensity values.
    \begin{center}
      \begin{tikzpicture}
      \begin{axis}[
        width=0.7\linewidth, height=4cm,
        ymin=0, ylabel={Count}, xlabel={Gray level $k$},
        xtick={0,64,128,192,255},
        xticklabel style={font=\footnotesize}, yticklabel style={font=\footnotesize},
        title={Bright Image Intensity Curve}
      ]
      % Smooth curve through the points
      \addplot[
        smooth, thick, blue
      ] coordinates {
        (0,2) (32,5) (64,10) (96,18) (128,30) (160,40) (192,55) (224,60) (255,58)
      };
      \end{axis}
      \end{tikzpicture}
      \\
      \emph{Intensity profile of a bright image: curve shifted towards high gray levels}
    \end{center}
    \item A \textbf{dark image} shows histogram concentrated on low values.
    \begin{center}
      \begin{tikzpicture}
      \begin{axis}[
        width=0.7\linewidth, height=4cm,
        ymin=0, ylabel={Count}, xlabel={Gray level $k$},
        xtick={0,64,128,192,255},
        xticklabel style={font=\footnotesize}, yticklabel style={font=\footnotesize},
        title={Dark Image Intensity Curve}
      ]
      % Smooth curve through the points
      \addplot[
        smooth, thick, blue
      ] coordinates {
        (0,60) (32,55) (64,40) (96,30) (128,18) (160,10) (192,5) (224,2) (255,2)
      };
      \end{axis}
      \end{tikzpicture}
      \\
      \emph{Intensity profile of a dark image: curve shifted towards low gray levels}
    \end{center}
    \item A \textbf{dual-peak image} indicates presence of both dark (background) and bright (foreground) regions.
    \begin{center}
      \begin{tikzpicture}
      \begin{axis}[
        width=0.7\linewidth, height=4cm,
        ymin=0, ylabel={Count}, xlabel={Gray level $k$},
        xtick={0,64,128,192,255},
        xticklabel style={font=\footnotesize}, yticklabel style={font=\footnotesize},
        title={Dual-Peak Image Intensity Curve}
      ]
      % Smooth curve through the points
      \addplot[
        smooth, thick, blue
      ] coordinates {
        (0,22) (32,30) (64,76) (96,30) (128,15) (160,27) (192,44) (224,29) (255,23)
      };
      \end{axis}
      \end{tikzpicture}
      \\
      \emph{Intensity profile of a dual-peak image: two distinct peaks at low and high gray levels}
    \end{center}

    \item A \textbf{flat histogram} corresponds to uniformly distributed intensities.
    \begin{center}
      \begin{tikzpicture}
      \begin{axis}[
        width=0.7\linewidth, height=4cm,
        ymin=0, ylabel={Count}, xlabel={Gray level $k$},
        xtick={0,64,128,192,255},
        xticklabel style={font=\footnotesize}, yticklabel style={font=\footnotesize},
        title={Flat Image Intensity Curve}
      ]
      % Smooth curve through the points
      \addplot[
        smooth, thick, blue
      ] coordinates {
        (0,22) (32,20) (64,19) (96,20) (128,21) (160,20) (192,21) (224,21) (255,22)
      };
      \end{axis}
      \end{tikzpicture}
      \\
      \emph{Intensity profile of a flat image: uniform distribution across all gray levels}
    \end{center}

\end{itemize}

\textbf{At a Glance:}

\begin{center}
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{@{}p{3.2cm}p{4.8cm}p{4.8cm}@{}}
\toprule
\textbf{Histogram Type} & \textbf{Typical Scene} & \textbf{Segmentation Implication} \\
\midrule
Dark-skewed & Low-light or dark objects & Threshold near lower gray levels \\
Bright-skewed & Bright background/lighting & Threshold near higher gray levels \\
Bimodal & Foreground vs.\ background & Global threshold often effective \\
Flat/noisy & Low contrast/high noise & Consider contrast stretch or adaptive threshold \\
\bottomrule
\end{tabular}
\end{center}


}


\section{Binarization}

Binarization is the process of converting a grayscale image into a binary image, where each pixel is assigned a value of either 0 (black) or 1 (white). This is typically done by applying a threshold to the image, such that pixels above the threshold are set to 1 and those below are set to 0.
\[
B(x,y) = \begin{cases}
1 & I(x,y) \geq T \\
0 & I(x,y) < T
\end{cases}
\]
where $T$ is the threshold.

Choosing an appropriate threshold is crucial for effective binarization. we can use histogram-based methods to select the threshold, by first order statistics or second order statistics (Otsu's method).

\subsection{Probability and Statistical Prerequisites}

\paragraph{Basic Probability Concepts}
Consider an image histogram with $L$ gray levels ($0, 1, ..., L-1$). Let $p_k$ denote the normalized probability for gray level $k$:
$$
p_k = \frac{n_k}{N}
$$
where $n_k$ is the number of pixels with gray level $k$, and $N$ is the total pixel count.

\subsubsection{Class Probabilities, Means, and Variances}
For a given threshold $T$:

\noindent \textbf{Class Probability}
\begin{itemize}
\item Probability that the pixel belongs to class 0 (background)
\[
\omega_0(T) = \sum_{k=0}^T p _k \quad\text{(Probability of class 0 - background - black pixels)}
\]
\item Probability that the pixel belongs to class 1 (foreground)
\[\omega_1(T) = \sum_{k=T+1}^{L-1} p_k \quad\text{(Probability of class 1 - foreground - white pixels)} 
\]
\end{itemize}

\noindent \textbf{Class Means} 
\begin{itemize}
  

\item  Probability that the pixel takes values k given that it belongs to class 0
\begin{align*}
\mu_0(T) &= \sum_{k=0}^T k \cdot p(k | C_0)  \quad\text{(Mean of class 0)} \\
\text{where} \quad p(k | C_0) &= \frac{p(k, C_0)}{p(C_0)} = \frac{p_k p(C_0 | k)}{p(C_0)} \\
\text{for} k \in \{ 0\dots T \} \quad p(k | C_0) &= \frac{p_k}{\omega_0(T)} \\
\mu_0(T) &=\frac{1}{\omega_0(T)} \sum_{k=0}^T k p_k \\
\text{also, for} k \in \{ T+1 \dots L-1 \} \quad p(k | C_0) &= 0\\ 
\mu_0(T) &=\frac{1}{\omega_0(T)} \sum_{k=0}^{L-1} k p_k
\end{align*}
\item Probability that the pixel takes values k given that it belongs to class 1
\begin{align*}
\mu_1(T) &= \sum_{k=T+1}^{L-1} k \cdot p(k | C_1)  \quad\text{(Mean of class 1)} \\
\text{where} \quad p(k | C_1) &= \frac{p(k, C_1)}{p(C_1)} = \frac{p_k p(C_1 | k)}{p(C_1)} \\
\text{for} k \in \{ T+1 \dots L-1 \} \quad p(k | C_1) &= \frac{p_k}{\omega_1(T)} \\
\mu_1(T) &=\frac{1}{\omega_1(T)} \sum_{k=T+1}^{L-1} k p_k \\
\text{also, for} k \in \{ 0 \dots T \} \quad p(k | C_1) &= 0\\
\mu_1(T) &=\frac{1}{\omega_1(T)} \sum_{k=0}^{L-1} k p_k
\end{align*}

\item Overall Image Mean
\begin{align*}
\mu_T &= \sum_{k=0}^{L-1} k p_k \\
&= \sum_{k=0}^{T} k p_k + \sum_{k=T+1}^{L-1} k p_k\\ 
&= \mu_0(T) \omega_0(T) + \mu_1(T) \omega_1(T)
\end{align*}
\end{itemize}

\noindent \textbf{Class Variances}\\
\begin{itemize}
\item Variance of class 0
\begin{align*}
\sigma_0^2(T) &= \sum_{k=0}^{T} (k - \mu_0(T))^2 p(k | C_0)\\
&= \sum_{k=0}^{T} (k - \mu_0(T))^2 \frac{p_k}{\omega_0(T)}
\end{align*}

\item Variance of class 1
\begin{align*}
\sigma_1^2(T) &= \sum_{k=T+1}^{L-1} (k - \mu_1(T))^2 p(k | C_1)\\
&= \sum_{k=T+1}^{L-1} (k - \mu_1(T))^2 \frac{p_k}{\omega_1(T)}
\end{align*}

\item Total Image Variance
\begin{align*}
  \sigma^2 (T) &= \sum_{k=0}^{L-1} (k - \mu_T)^2 p_k \\
  &= \sum_{k=0}^{T} (k - \mu_T)^2 p_k + \sum_{k=T+1}^{L-1} (k - \mu_T)^2 p_k \\
  &= \sigma_0^2(T) + \sigma_1^2(T) + \omega_0(T)[\mu_0(T) - \mu_T]^2 + \omega_1(T)[\mu_1(T) - \mu_T]^2
\end{align*}
\end{itemize}

\dfn{Within Class Variance $\sigma_w^2(T)$}{
  The variance of pixel intensities within class is given by:
  \begin{align*}
  \sigma_w^2(T) &= \omega_0(T) \sigma_0^2(T) + \omega_1(T) \sigma_1^2(T)
  \end{align*}

  Also known as intra-class variance, $\sigma_w^2(T)$ measures the compactness of pixel intensities within each class. \textbf{maximizing} $\sigma_w^2(T)$ leads to better class separability.
}

\dfn{Between Class Variance $\sigma_b^2(T)$}{
  The variance of pixel intensities between class is given by:
  \begin{align*}
  \sigma_b^2(T) &= \sigma^2 - \sigma_w^2(T) \\
  &= \sigma^2 - \left( \omega_0(T) \sigma_0^2(T) + \omega_1(T) \sigma_1^2(T) \right)\\
  &= \omega_0(T) \omega_1(T) \left[ \mu_0(T) - \mu_1(T) \right]^2
  \end{align*}

  Also known as inter-class variance, $\sigma_b^2(T)$ measures the separability of pixel intensities between classes. \textbf{minimizing} $\sigma_w^2(T)$ leads to better class compactness.
}


\paragraph{Derivation of \(\sigma_b^2(T)\) from definition of \(\sigma_w^2(T)\)}

\begin{proof}[Derivation of \(\sigma_b^2(T)\)]
  
\begin{align*}
  \sigma^2 & = \sigma_w^2(T) + \sigma_b^2(T) \\
  \sigma_b^2(T) & = \sigma^2 - \sigma_w^2(T)\\
  &= \sigma^2 - \left( \omega_0(T) \sigma_0^2(T) + \omega_1(T) \sigma_1^2(T) \right)\\
\end{align*}

Now, expand the total variance \(\sigma^2\).  
Let \(\mu = \omega_0\mu_0 + \omega_1\mu_1\) be the global mean. 
let's also ignore $(T)$ for simplicity.
Then
\begin{align*}
  \sigma^2 &= \sum_{i} \omega_i \big(\sigma_i^2 + \mu_i^2\big) - \mu^2 \\[6pt]
           &= \omega_0(\sigma_0^2 + \mu_0^2) + \omega_1(\sigma_1^2 + \mu_1^2) - \mu^2.
\end{align*}

Substitute this back:
\begin{align*}
  \sigma_b^2(T)
  &= \Big[\omega_0(\sigma_0^2 + \mu_0^2) + \omega_1(\sigma_1^2 + \mu_1^2) - \mu^2\Big]
     - \Big(\omega_0\sigma_0^2 + \omega_1\sigma_1^2\Big) \\[6pt]
  &= \omega_0\mu_0^2 + \omega_1\mu_1^2 - \mu^2.
\end{align*}

Since \(\mu = \omega_0\mu_0 + \omega_1\mu_1\), we expand:
\begin{align*}
  \sigma_b^2(T)
  &= \omega_0\mu_0^2 + \omega_1\mu_1^2 - \big(\omega_0\mu_0 + \omega_1\mu_1\big)^2 \\[6pt]
  &= \omega_0\mu_0^2 + \omega_1\mu_1^2
     - \big(\omega_0^2\mu_0^2 + \omega_1^2\mu_1^2 + 2\omega_0\omega_1\mu_0\mu_1\big) \\[6pt]
  &= \omega_0(1-\omega_0)\mu_0^2 + \omega_1(1-\omega_1)\mu_1^2 - 2\omega_0\omega_1\mu_0\mu_1 \\[6pt]
  &= \omega_0\omega_1\mu_0^2 + \omega_0\omega_1\mu_1^2 - 2\omega_0\omega_1\mu_0\mu_1 \\[6pt]
  &= \omega_0\omega_1(\mu_0 - \mu_1)^2.
\end{align*}
  
\end{proof}

\subsection{Thresholding using First Order statistics}
Thresholding using first-order statistics involves selecting a threshold based on the mean or median intensity values of the image histogram. The basic idea is to compute a global threshold that separates the foreground from the background by analyzing the intensity distribution.

\paragraph{Mean Thresholding} The threshold is set to the mean intensity value of the image.
   \[
   T = \frac{1}{N} \sum_{x,y} I(x,y)
   \]
   where \(N\) is the total number of pixels.

\paragraph{Median Thresholding} The threshold is set to the median intensity value, which is more robust to outliers.
   \[
   T = \text{median}(I(x,y))
   \]

These methods are simple and computationally efficient but may not perform well for images with complex backgrounds or varying illumination.

\subsection{Otsu’s Binarization}

Otsu's Binarization method uses Second Order Statistics to find the optimal threshold for image binarization.

\dfn{Otsu’s Binarization}{The process of determining the threshold $T^*$ that maximizes the inter-class variance between foreground and background, thus optimally segmenting a bimodal histogram image.}

\paragraph{Optimization Criteria}

Otsu’s method selects a threshold $T^*$ to partition the image pixels into two classes (often foreground and background) so that the variance between these classes (\textbf{inter-class variance}) is maximized, or equivalently, the variance within each class (\textbf{intra-class variance}) is minimized. These criteria are mathematically dual—maximizing $\sigma_b^2(T)$ is identical to minimizing $\sigma_w^2(T)$ since their sum is the total variance $\sigma^2$.

\begin{center}
\begin{tikzpicture}[scale=1.2]
    % Axis
    \draw[->] (0,0) -- (5,0) node[right] {Intensity};
    \draw[->] (0,0) -- (0,3) node[above] {Histogram};
    % Bimodal histogram
    \draw[domain=0.3:2.3,smooth,variable=\x,blue,thick] plot (\x,{2*exp(-2*(\x-1)^2)});
    \draw[domain=2.7:4.7,smooth,variable=\x,red,thick] plot (\x,{2*exp(-2*(\x-4)^2)});
    % Threshold line at T
    \draw[dashed] (2.5,0) -- (2.5,2) node[above] {$T^*$};
\end{tikzpicture}

\textit{A typical bimodal histogram: $T^*$ chosen to best separate two peaks.}
\end{center}

\clm{Equivalence of Maximization and Minimization Criteria}{}{
Maximizing the between-class variance $\sigma_b^2(T)$ is equivalent to minimizing within-class variance $\sigma_w^2(T)$, as
\[
\arg\max_T \sigma_b^2(T) = \arg\min_T \sigma_w^2(T)
\]
since $\sigma^2$ is fixed for a given image histogram.
}
\nt{In practice, Otsu's method typically maximizes $\sigma_b^2(T)$, but formulations based on minimizing $\sigma_w^2(T)$ yield the same optimal threshold $T^*$.}

\subsection{Method 1: Maximization of Inter-Class Variance}

Threshold $T^*$ is selected to maximize the between-class variance $\sigma_b^2(T)$.
$$
  T^* = \arg\max_T \sigma_b^2(T) = \arg\max_T \left[ \omega_0(T) \omega_1(T) \left( \mu_0(T) - \mu_1(T) \right)^2 \right]
$$

\noindent The algorithm for Otsu's binarization by maximizing $\sigma_b^2(T)$ is as follows:

\begin{enumerate}
    \item Compute the histogram and probabilities $p_i = n_i/N$ for each gray level $i$.
    \item For each possible threshold $T$ (from gray level $1$ to $L-2$):
    \begin{itemize}
        \item Calculate class weights (probabilities): $\omega_0(T)$ and $\omega_1(T)$.
        \item Calculate class means: $\mu_0(T)$ and $\mu_1(T)$.
        \item Compute between-class variance:
            \[
            \sigma_b^2(T) = \omega_0(T)\,\omega_1(T)\left[\mu_0(T) - \mu_1(T)\right]^2
            \]
    \end{itemize}
    \item Find the threshold $T^*$ that maximizes $\sigma_b^2(T)$.
\end{enumerate}

\ex{Numerical Example}{
Suppose an image has normalized histogram values:
$
p_0 = 0.4, \quad p_1 = 0.2, \quad p_2 = 0.2, \quad p_3 = 0.2
$
Try threshold $T = 1$:
\begin{align*}
\omega_0(1) &= p_0 + p_1 = 0.6\\
\omega_1(1) &= 0.4\\
\mu_0(1) &= \frac{0 \cdot 0.4 + 1 \cdot 0.2}{0.6} = 0.333\\
\mu_1(1) &= \frac{2 \cdot 0.2 + 3 \cdot 0.2}{0.4} = 2.5
\end{align*}
Now,
\[
\sigma_b^2(1) = 0.6 \times 0.4 \times (0.333 - 2.5)^2 \approx 0.6 \times 0.4 \times 4.694 \approx 1.126
\]
similarly for $T=2$:
\begin{align*}
\omega_0(2) &= p_0 + p_1 +p_2 = 0.8\\
\omega_1(2) &= 0.2\\
\mu_0(2) &= \frac{0 \cdot 0.4 + 1 \cdot 0.2 + 2 \cdot 0.2}{0.8} = 0.75\\
\mu_1(2) &= \frac{3 \cdot 0.2}{0.2} = 3
\end{align*}
Now,
\[
\sigma_b^2(2) = 0.8 \times 0.2 \times (0.75 - 3)^2 \approx 0.8 \times 0.2 \times 5.0625 \approx 0.81
\]

\begin{center}
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{c|c|c|c|c|c}
\toprule
$T$ & $\omega_0(T)$ & $\omega_1(T)$ & $\mu_0(T)$ & $\mu_1(T)$ & $\sigma_b^2(T)$ \\
\midrule
1 & 0.6 & 0.4 & 0.3333 & 2.5 & \textbf{1.1267} \\
2 & 0.8 & 0.2 & 0.75 & 3 & 0.81 \\
\bottomrule
\end{tabular}
\end{center}

\[
\boxed{\text{Maximum } \sigma_b^2 \text{ occurs at } T=1, \quad
\sigma_b^2(1)\approx \mathbf{1.1267}.}
\]

}

\subsection{Method 2: Minimization of Within-Class Variance}

Threshold $T^*$ is selected to minimize the within-class variance $\sigma_w^2(T)$.
$$
  T^* = \arg\min_T \sigma_w^2(T) = \arg\min_T \left[ \omega_0(T) \sigma_0^2(T) + \omega_1(T) \sigma_1^2(T) \right]
$$

\noindent This approach explicitly minimizes intra-class variance $\sigma_w^2(T)$.

\begin{enumerate}
    \item For each threshold $T$, calculate:
    \begin{align*}
        \sigma_w^2(T) = \omega_0(T) \sigma_0^2(T) + \omega_1(T) \sigma_1^2(T)
    \end{align*}
    where $\sigma_k^2(T)$ are variances for classes $k=0,1$, based on histogram statistics within each class.
    \item Find $T^*$ that minimizes $\sigma_w^2(T)$.
\end{enumerate}



\clm{Proof of Equivalence}{}{
Since $\sigma^2 = \sigma_w^2(T) + \sigma_b^2(T)$ for all $T$, maximizing $\sigma_b^2(T)$ is the same as minimizing $\sigma_w^2(T)$.

Now, because \(\sigma^2\) is independent of \(T\), for two thresholds \(T_1,T_2\) we have
\[
\sigma_b^2(T_1) > \sigma_b^2(T_2)
\quad\Longleftrightarrow\quad
\sigma_w^2(T_1) < \sigma_w^2(T_2),
\]
since subtracting the same constant \(\sigma^2\) from both sides reverses neither inequalities nor signs but simply gives
\[
\sigma^2 - \sigma_b^2(T_1) < \sigma^2 - \sigma_b^2(T_2)
\quad\Longleftrightarrow\quad
\sigma_w^2(T_1) < \sigma_w^2(T_2).
\]
Therefore
\[
\;\arg\max_T \sigma_b^2(T)\;=\;\arg\min_T \sigma_w^2(T)\;
\]

Equivalently, using the explicit form \[\sigma_b^2(T)=\omega_0(T)\,\omega_1(T)\big(\mu_0(T)-\mu_1(T)\big)^2\]
maximizing this expression over \(T\) yields the same \(T\) that minimizes \(\sigma_w^2(T)\) because
\[
\sigma_w^2(T)=\sigma^2-\sigma_b^2(T).
\]
Hence any \(T\) that increases the between-class separation \(\omega_0\omega_1(\mu_0-\mu_1)^2\) necessarily reduces the within-class scatter and vice versa.

Thus,
\begin{align*}
\text{Maximize } \sigma_b^2(T) &\Leftrightarrow \text{Minimize } \sigma_w^2(T) \\
\end{align*}

}
\nt{
\begin{itemize}
  \item The identity relies on \(\sigma^2\) being fixed (global histogram is fixed). If the data used to compute \(\sigma^2\) changed with \(T\), the equivalence would not hold.
  \item Since \(\omega_0,\omega_1\ge 0\) and \(\mu_0,\mu_1\) are real, \(\sigma_b^2(T)\ge 0\). Maximizing \(\sigma_b^2\) therefore finds the threshold giving the largest possible separation between class means (weighted by class sizes), which is precisely the threshold that minimizes the residual within-class variance.
\end{itemize}
}

\subsection{Algorithm: Otsu’s Binarization (most used)}

\begin{enumerate}
    \item Compute image histogram.
    \item For each threshold $T$:
    \begin{itemize}
        \item Partition pixels into two classes.
        \item Compute $\omega_k(T)$, $\mu_k(T)$, $\sigma_k^2(T)$ as needed.
        \item Compute either $\sigma_b^2(T)$ or $\sigma_w^2(T)$.
    \end{itemize}
    \item Determine $T^*$ by maximizing $\sigma_b^2(T)$ or minimizing $\sigma_w^2(T)$.
    \item Binarize the image: pixels $\leq T^*$ are assigned to class 0; others to class 1.
\end{enumerate}

\nt{Otsu’s method is most effective for bimodal histograms, but may be suboptimal for multi-modal or unimodal histograms. Variations and generalizations (multi-level, local thresholding) exist for more complex cases.}


\section{Connected Component Analysis}

A \emph{connected component} in a binary image is a maximal group of adjacent foreground pixels, where adjacency is defined by connectivity (typically, 4-connected or 8-connected).

\dfn{Connected Component}{A subset of foreground pixels $(p, q)$ such that for any pixel $p$ in the subset, there exists a sequence of pixels in the subset linking $p$ to $q$ via connected neighbors.

\begin{center}
\begin{tikzpicture}[scale=1.2]
% Draw grid
\foreach \x in {0,1,2,3}
  \foreach \y in {0,1,2}
    \draw[gray!50] (\x,\y) rectangle ++(1,1);

% Fill foreground pixels (1s)
\fill[black!80] (1,2) rectangle ++(1,1); % (1,0)
\fill[black!80] (2,2) rectangle ++(1,1); % (2,0)
\fill[black!80] (2,1) rectangle ++(1,1); % (2,1)
\fill[black!80] (0,0) rectangle ++(1,1); % (0,2)
\fill[black!80] (3,0) rectangle ++(1,1); % (3,2)

% Add labels
\node at (0.5,2.5) {\textcolor{white}{1}};
\node at (1.5,2.5) {\textcolor{white}{1}};
\node at (2.5,2.5) {\textcolor{white}{1}};
\node at (3.5,2.5) {0};
\node at (0.5,1.5) {0};
\node at (1.5,1.5) {0};
\node at (2.5,1.5) {\textcolor{white}{1}};
\node at (3.5,1.5) {0};
\node at (0.5,0.5) {\textcolor{white}{1}};
\node at (1.5,0.5) {0};
\node at (2.5,0.5) {0};
\node at (3.5,0.5) {\textcolor{white}{1}};

% Draw 4-connectivity lines for the top component
\draw[red,thick] (1.5,2.5) -- (2.5,2.5); % horizontal
\draw[red,thick] (2.5,2.5) -- (2.5,1.5); % vertical

% Draw 4-connectivity for bottom left and right
% (0,0) and (3,0) are isolated (no lines needed)

% Add component labels
\node[red] at (2.1,2.1) {\small C1};
\node[green] at (0.5,0.2) {\small C2};
\node[orange] at (3.5,0.2) {\small C3};

\end{tikzpicture}
\\
\emph{Illustration of 4-connected components in a binary image}
\end{center}

}

\paragraph{Connectivity}
\begin{itemize}
    \item \textbf{4-Connectivity:} Each pixel is connected to its immediate horizontal and vertical neighbors.

    Neighbors for a pixel $(x,y)$ are $$\{ (x-1,y), (x+1,y), (x,y-1), (x,y+1)\}$$
    \begin{center}
    \begin{tikzpicture}[scale=1.2]
    % Draw 3x3 grid
    \foreach \x in {0,1,2}
      \foreach \y in {0,1,2}
        \draw[gray!50] (\x,\y) rectangle ++(1,1);

    % Highlight center pixel
    \fill[blue!60] (1,1) rectangle ++(1,1);
    \node at (1.5,1.5) {\textcolor{white}{P}};

    % Highlight 4-neighbors
    \fill[red!60] (0,1) rectangle ++(1,1); % left
    \fill[red!60] (2,1) rectangle ++(1,1); % right
    \fill[red!60] (1,0) rectangle ++(1,1); % below
    \fill[red!60] (1,2) rectangle ++(1,1); % above

    % Add plus symbol
    \draw[thick,->] (1.5,1.7) -- (1.5,2.3); % up
    \draw[thick,->] (1.5,1.3) -- (1.5,0.7); % down
    \draw[thick,->] (1.3,1.5) -- (0.7,1.5); % left
    \draw[thick,->] (1.7,1.5) -- (2.3,1.5); % right

    % Neighbor labels 
    \node at (0.5,1.5) {\textcolor{white}{N}};
    \node at (2.5,1.5) {\textcolor{white}{N}};
    \node at (1.5,2.5) {\textcolor{white}{N}};
    \node at (1.5,0.5) {\textcolor{white}{N}};

    \end{tikzpicture}
    \\
    \emph{Plus-shaped 4-neighborhood of pixel $P$}
    \end{center}
    \item \textbf{8-Connectivity:} Includes diagonal neighbors as well.

    Neighbors for a pixel $(x,y)$ are $$\{ (x-1,y), (x+1,y), (x,y-1), (x,y+1), (x-1,y-1), (x-1,y+1), (x+1,y-1), (x+1,y+1) \}$$ 

\end{itemize}

\dfn{Path}{
  Path from $(x,y)$ to $(s,t)$ is a sequence of pixels $\{(x_0,y_0), (x_1,y_1), \ldots, (x_n,y_n)\}$ where $(x_0,y_0) = (x,y)$, $(x_n,y_n) = (s,t)$, and each consecutive pair of pixels are connected according to the chosen connectivity (4 or 8).   
}

\dfn{Connectedness}{
  the pixels $(x,y)$ and $(s,t)$ are connected if there exists a path between them consisting entirely of same polarity pixels (all foreground or all background).
}

\noindent A \textbf{4-Connected Component} is a set of pixels that are connected to each other through 4-connectivity paths. 

\subsection{Extraction of Connected Components}

\clm{Labeling Algorithms}{}{
Every pixel belonging to a connected component can be assigned a unique label using the connected component labeling algorithm.
}

\dfn{Region index array}{
  Region index array is a matrix of the same size as the binary image, where each pixel is assigned a label (integer) corresponding to the connected component it belongs to. Background pixels are typically labeled as 0.
}

\noindent The goal is to assign distinct labels to all connected components in a binary image.

\paragraph{Labeling Algorithm}
\begin{enumerate}
    \item Scan the image pixel by pixel in a defined order (e.g., left-to-right, top-to-bottom).
    \item For each foreground pixel, examine its neighbors (depending on the connectivity rule).
    \item Assign a new label if no neighbor is labeled; otherwise assign the neighbor’s label.
    \item If multiple labeled neighbors, assign one and record equivalences.
    \item After complete pass, resolve label equivalences: assign unique labels to all connected components.
\end{enumerate}

\ex{Connected Component Labeling}{
Say, Given the binary image (rows indexed from 1):
\[
B=\begin{matrix}
0 & 1 & 1 & 0\\
0 & 0 & 1 & 0\\
1 & 0 & 0 & 1
\end{matrix}
\]

We use \emph{4-connectivity} and the standard two-pass algorithm (scan row-major). Denote left neighbour by \(N_L\) and up neighbour by \(N_U\). Maintain a provisional label counter \(L\) (start \(L\gets 1\)) and an equivalence table (for union-find).


\textbf{First pass (scan, assign provisional labels and record equivalences).}

\medskip
Scan order (only foreground pixels shown). For each foreground pixel we inspect \(N_L,N_U\) and apply the standard rules:
\begin{itemize}
  \item if both neighbours background, \(\Rightarrow\) assign new label \(L\), increment \(L\);

  if $I(i-1,j) = I(i,j-1) = 0$ then, $R(i,j) = L$ and $L++$.

  \item if only one neighbour is labelled \(\Rightarrow\) copy that label;
  
  if $I(i-1,j) = M $ or $I(i,j-1) = M$ then, $R(i,j) = M$.

  \item if both neighbours labelled with different labels \(\Rightarrow\) assign one of them and record their equivalence.

  if $I(i-1,j) = M $ and $I(i,j-1) = N$ then, $R(i,j) = M$ and record equivalence $M \sim N$.

\end{itemize}
\begin{center}
  \begin{tabular}{@{}cccccl@{}}
    \toprule
    Step & Pixel & \(N_L\) & \(N_U\) & Action & Result / equivalences \\ \midrule
    1 & \((1,2)\) & \(0\) & none & both background $\Rightarrow$ new label & assign \(1\). \(L\gets 2\). \\
    2 & \((1,3)\) & \(1\) & none & left labelled & assign \(1\). \\
    3 & \((2,3)\) & \(0\) & \(1\) & up labelled & assign \(1\). \\
    4 & \((3,1)\) & none & \(0\) & both background & assign \(2\). \(L\gets 3\). \\
    5 & \((3,4)\) & \(0\) & \(0\) & both background & assign \(3\). \(L\gets 4\). \\ \bottomrule
  \end{tabular}
\end{center}

  \vspace{6pt}
  Note: no step produced conflicting labels from \(N_L\) and \(N_U\), hence no equivalences were recorded (equivalence sets remain \(\{1\},\{2\},\{3\}\)).

Provisional labelled image (Region) after first pass:
\[
R^{(1)}=
\begin{matrix}
0 & 1 & 1 & 0\\
0 & 0 & 1 & 0\\
2 & 0 & 0 & 3
\end{matrix}
\]

\textbf{Equivalence resolution (union-find / flattening).}

Equivalence table (pairs recorded during first pass): none in this example. Therefore canonical representatives are
\[
\mathrm{repr}(1)=1,\quad \mathrm{repr}(2)=2,\quad \mathrm{repr}(3)=3.
\]

\textbf{Second pass (replace provisional labels by their canonical representatives).}

Apply \[R_{\text{final}}(x,y)\leftarrow\mathrm{repr}\big(R^{(1)}(x,y)\big)\]
Since representatives are identity, the final labelled image is
\[
R_{\text{final}}=
\begin{matrix}
0 & \mathbf{1} & \mathbf{1} & 0\\
0 & 0 & \mathbf{1} & 0\\
\mathbf{2} & 0 & 0 & \mathbf{3}
\end{matrix}
\]

\textbf{Components (explicit pixel sets).}
\[
\mathcal{C}_1=\{(1,2),(1,3),(2,3)\},\quad
\mathcal{C}_2=\{(3,1)\},\quad
\mathcal{C}_3=\{(3,4)\}.
\]

}

\nt{
Correctly extracting connected components is crucial for counting objects, segmenting regions, and preparing for further analysis such as shape feature extraction.
}


\section{Binary Image Filters}

Binary images require specialized filtering techniques to process and enhance them, typically via mathematical morphology.

\subsection{Window}

A \textbf{window} or \textbf{kernel} in filtering is a small submatrix (usually square, e.g., $3 \times 3$) that moves systematically over the image, determining how each pixel should be transformed based on its neighborhood.

\subsubsection{1D Window}

In 1D signals, a window is a segment of the signal used for processing. For example, a $3$-point window might include samples $x[m, n-1], x[m, n], x[m, n+1]$ for a row window and $x[m-1, n], x[m, n], x[m+1, n]$ for a column window.

\begin{center}
\begin{tikzpicture}[scale=1.2]
% Draw 3x3 grid
\foreach \x in {0,1,2}
  \foreach \y in {0,1,2}
    \draw[gray!50] (\x,\y) rectangle ++(1,1);

% Row window: highlight center row
\foreach \x in {0,1,2}
  \fill[blue!30] (\x,1) rectangle ++(1,1);

% Mark center pixel
\fill[blue!60] (1,1) rectangle ++(1,1);
\node at (1.5,1.5) {\textcolor{white}{P}};

% Row window label
\node[below] at (1.5,-0.2) {Row Window};

\end{tikzpicture}
\hspace{1cm}
\begin{tikzpicture}[scale=1.2]
% Draw 3x3 grid
\foreach \x in {0,1,2}
  \foreach \y in {0,1,2}
    \draw[gray!50] (\x,\y) rectangle ++(1,1);

% Column window: highlight center column
\foreach \y in {0,1,2}
  \fill[red!30] (1,\y) rectangle ++(1,1);

% Mark center pixel
\fill[red!60] (1,1) rectangle ++(1,1);
\node at (1.5,1.5) {\textcolor{white}{P}};

% Column window label
\node[below] at (1.5,-0.2) {Column Window};

\end{tikzpicture}
\end{center}

\subsubsection{2D Window}

Windows are mostly non-casual, means pixels can be influenced by their neighbors in both dimensions. A window can be defined as a rectangular region centered around a pixel, encompassing its surrounding pixels. 

Few shapes include square, Cross, circle, diamond, etc.

\paragraph{Common Window Shapes}
\begin{center}
\begin{tabular}{cc}
\textbf{Square} &
\textbf{Cross}  \\
% Square window
\begin{tikzpicture}
\foreach \x in {0,1,2}
  \foreach \y in {0,1,2}
    \draw[gray!60] (\x,\y) rectangle ++(1,1);
\foreach \x in {0,1,2}
  \foreach \y in {0,1,2}
    \fill[blue!40] (\x,\y) rectangle ++(1,1);
\end{tikzpicture}
&
% Cross window
\begin{tikzpicture}
\foreach \x in {0,1,2}
  \foreach \y in {0,1,2}
    \draw[gray!60] (\x,\y) rectangle ++(1,1);
\foreach \i in {0,1,2}
  \fill[red!40] (1,\i) rectangle ++(1,1);
\foreach \i in {0,1,2}
  \fill[red!40] (\i,1) rectangle ++(1,1);
\end{tikzpicture}
\end{tabular}
\end{center}

\subsection{Binary Morphology}

A set of techniques used in image processing for analyzing and processing binary images based on shapes. It involves operations that probe and transform the structure of objects in the image using a defined window (structuring element).

\paragraph{Window Notation}
Let,
\[
B_i = (p_i, q_i) \quad \text{s.t.} \quad (p_i, q_i) \in B 
\]

then, A window is given as, 

\[
B = \{ B_1, B_2, B_3, \dots, B_{2p+1} \}
\]

\ex{Window Example}{
Consider a ROW window with $p$ pixels centered at $(0,0)$:
\[
\text{ROW}(2p+1) = \{(-p,0), (-p+1,0), \ldots, (0,0), \ldots, (p-1,0), (p,0)\}
\]

Consider a SQUARE $3 \times 3$ window centered at pixel $(0,0)$:
\[
\text{SQUARE}(9) = \{(-1,-1), (-1,0), (-1,1), (0,-1), (0,0), (0,1), (1,-1), (1,0), (1,1)\}
\]
}

\paragraph{Window Set} Given a image I and a Window B, the window set is given as 
\[
B \downarrow I(i,j) = \{I(i +p, j+q) | (p,q) \in B\}
\]


\subsection{Image Edges and Window Boundaries}

Applying filters near image edges requires care, as the window may extend outside the image domain. Strategies include:
\begin{itemize}
    \item \textbf{Padding:} Extend image with zeros or mirrored edges.
    \item \textbf{Ignore:} Only process central pixels with complete neighborhoods.
    \item \textbf{Wrap-around:} For mathematical convenience (rare in practice).
\end{itemize}

\subsection{Binary Filter}

\dfn{Binary Filter}{A transformation applied to a binary image using a specified window (kernel), resulting in output pixels determined by logical operations (AND, OR, etc.) on the neighborhood.}

\noindent Let G be a binary operation on a windowed set, then the binary filtered image is given as:
\[
J(i,j) = G(B \downarrow I(i,j)) \qquad \forall (i,j) \in I
\]


\nt{In morphological operations, careful handling of edges is necessary to avoid artifacts such as unwanted erosion or dilation at the image boundaries.}

\subsubsection{Fundamental Morphological Operations}

Mathematical morphology operates using set theory to process shapes in binary images. The two core operations are \textbf{dilation} and \textbf{erosion}, with further derived operations.

\dfn{Dilation}{For a binary image $I$ and structuring element $B$, the dilation $ J = \text{DILATE}(I,B) = I \oplus B$ is defined as:
$$
J(i,j) = OR \{ B \downarrow I(i,j) \}
$$

where $$OR\{x_1, x_2, \ldots, x_n\} = \bigvee_{k} x_k = x_1 +x2 + \ldots +x_n = \text{max}(x_1, x_2, \ldots, x_n)$$ is the logical OR operation or the Maximum pixel value picker over the set.
}

\dfn{Erosion}{For a binary image $I$ and structuring element $B$, the erosion $J = \text{ERODE}(I,B) = I \ominus B$ is:
$$
J(i,j) = AND \{ B \downarrow I(i,j) \}
$$

where $$AND\{x_1, x_2, \ldots, x_n\} = \bigwedge_{k} x_k = x_1 \cdot x_2 \cdot \ldots \cdot x_n = \text{min}(x_1, x_2, \ldots, x_n)$$ is the logical AND operation or the Minimum pixel value picker over the set.
}

\paragraph{Algorithmic Steps for binary image}
\begin{itemize}
    \item \textbf{Dilation:} For each pixel, if any neighbor within $B$ is foreground, set pixel to 1.
    \item \textbf{Erosion:} For each pixel, if all neighbors within $B$ are foreground, set pixel to 1; else 0.
\end{itemize}

\nt{Dilation expands object boundaries, while erosion shrinks them. The choice of structuring element $B$ (shape and size) significantly affects the outcome.}

\subsubsection{Duals}
Dilation and erosion are dual operations in mathematical morphology. This means that the dilation of the complement of an image is equal to the complement of the erosion of the image:
$$
\text{DILATE}(I^c, B) = (\text{ERODE}(I, B))^c
$$
where $I^c$ is the complement of the image $I$.

This comes straight from the definitions of dilation and erosion, as the operations are fundamentally linked through the concept of set complementation, i.e., $\bar{(x_1 + x_2)} = \bar{x_1} \cdot \bar{x_2}$.

\subsubsection{Derived Morphological Operations}

\paragraph{Majority Filter}
The majority filter is a simple yet effective morphological operation used to remove noise from binary images. It works by replacing each pixel's value with the majority value of its neighbors within a specified window. 
\[
J(i,j) = \text{MAJORITY} \{ B \downarrow I(i,j) \}
\]
This can help to smooth out small irregularities in the image.

\paragraph{Boundary Detection}

The boundary of objects in a binary image can be extracted as:
$$
\text{Boundary}(I) = \text{XOR}\{I, \text{ERODE}(I,B)\}
$$


\clm{Morphological Property}{}{
  \begin{itemize}
    \item Dilation expands, erosion shrinks, and their combinations (opening, closing) provide sophisticated noise removal and shape manipulation.
    \item Morphological operations are inherently non-linear, making them robust to noise and variations in object shape.
    \item Majority filter effectively reduces salt-and-pepper noise by enforcing local consistency.
    \item Boundary detection highlights object edges, aiding in shape analysis and recognition.
  \end{itemize}
}

